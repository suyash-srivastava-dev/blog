---
title: "NLP Pipeline Hugging Face"
seoTitle: "Hugging Face Pipeline in NLP"
seoDescription: "These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including NER"
datePublished: Sat Jun 24 2023 06:48:58 GMT+0000 (Coordinated Universal Time)
cuid: clj9n4b4e000409k603om9efd
slug: nlp-pipeline-hugging-face
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1687589151379/157f453c-b73c-47f0-a7d6-f0abf77c2e42.jpeg
tags: nlp, questions-and-answers, gpt-3, huggingface, nlp-transformers

---

## What is NLP Pipeline?

The NLP pipeline can be thought of as a funnel, with the raw text entering at the top and the final predictions emerging at the bottom. Each step in the pipeline helps to narrow the focus and extract more meaningful information from the text.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1687585486468/9313fea8-f86e-4d74-802c-18d487ec3184.jpeg align="center")

**There are three main steps involved when you pass some text to a pipeline:**

1. The text is preprocessed into a format the model can understand.
    
2. The preprocessed inputs are passed to the model.
    
3. The predictions of the model are post-processed, so you can make sense of them.
    

![](https://modeling-languages.com/wp-content/uploads/2019/07/Architecture-EncoderDecoder_v2.png align="center")

(will be covering each step in detail later ğŸ˜Š)

## The key task performed by NLP Pipeline ([Complete list](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.task))

* Sentiment-analysis
    
* Zero-shot classification
    
* fill-mask
    
* question-answering
    
* summarization
    
* text-generation
    
* translation
    

Will be covering codes for the above-mentioned task using hugging face.

<center>
<a target="_blank" href="https://colab.research.google.com/github/suyash-srivastava-dev/A4I/blob/main/Colab/NLP_01.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" />
</a>
</center>

## Steps to use pipeline from Hugging Face

**Step 1: Install the transformer library**

`!pip install transformers`

**Step 2: Use the pipeline from the transformer library**

```python
from transformers import pipeline
```

**Step 3: Use the task from the pipeline**

```python
classifier = pipeline("sentiment-analysis")
```

*or with a mentioned model (eg: specific to the financial market)*

```python
from transformers import pipeline
classifier = pipeline(model="ProsusAI/finbert")
classifier("stocks dropped 42% while Samsung rallied")
# [{'label': 'negative', 'score': 0.9670934081077576}]
```

**Step 4: Use the selected task pipeline for the task output generation for the given input.**

```python
classifier("This is the worst possible product. Nothing works in this.")
# [{'label': 'NEGATIVE', 'score': 0.9998025298118591}]
# model : distilbert-base-uncased-finetuned-sst-2-english
```

---

### **Zero-shot classification**

Zero-shot learning (ZSL) in NLP is a machine learning technique that allows a model to classify text from previously unseen classes, without receiving any specific training for those classes. This is done by leveraging the model's understanding of the semantic relationships between words and concepts.

There are two main approaches to ZSL in NLP:

* Attributes-based ZSL: This approach uses a set of attributes to describe the unseen classes. The model is then trained to map these attributes to class labels.
    
* Semantic-based ZSL: This approach uses a knowledge base to represent the semantic relationships between words and concepts. The model is then trained to use this knowledge base to make predictions about unseen classes.
    

```python
fromÂ transformersÂ importÂ pipeline

classifierÂ =Â pipeline("zero-shot-classification")
classifier(
Â Â Â Â "AirpodsÂ areÂ theÂ best",
Â Â Â Â candidate_labels=["education",Â "politics",Â "technology",Â "business"],
)
```

```bash
# Output
{'sequence': 'Airpods are the best',
 'labels': ['technology', 'business', 'education', 'politics'],
 'scores': [0.9303504228591919,
  0.048402491956949234,
  0.012988047674298286,
  0.008259052410721779]}
```

---

### **Text generation**

For the provided prompt, the model will auto-complete it by generating the remaining text. This is similar to the predictive text feature that is found on phones or the gmail next words suggestion.

```python
fromÂ transformersÂ importÂ pipeline

generatorÂ =Â pipeline("text-generation")
generator("AppleÂ isÂ oneÂ ofÂ theÂ biggest")
```

Output

```python
[{'generated_text': 'Apple is one of the biggest players in the PC gaming industry. The company recently signed licensing agreements with some very notable companies including AMD, NVIDIA, and Electronic Arts. PC gaming has been a huge success across the board, with the release of more copies'}]
```

---

### **Mask filling**

the task is to fill in the blanks in a given sentence.

```python
fromÂ transformersÂ importÂ pipeline

unmaskerÂ =Â pipeline("fill-mask")
unmasker("AppleÂ isÂ <mask>Â forÂ theÂ techÂ industry.",Â top_k=2)Â #top_kÂ isÂ toÂ limitÂ results,Â willÂ fetchÂ top_kÂ resultsÂ only
```

```python
[{'score': 0.08616828173398972,
  'token': 2149,
  'token_str': ' responsible',
  'sequence': 'Apple is responsible for the tech industry.'},
 {'score': 0.037314582616090775,
  'token': 12115,
  'token_str': ' bullish',
  'sequence': 'Apple is bullish for the tech industry.'}]
```

---

### **Question answering**

```python
fromÂ transformersÂ importÂ pipeline

question_answererÂ =Â pipeline("question-answering")
question_answerer(
Â Â Â Â question="WhatÂ isÂ aimÂ ofÂ ChatGPT",
Â Â Â Â context="ChatGPTÂ isÂ anÂ advancedÂ languageÂ modelÂ designedÂ toÂ assistÂ usersÂ withÂ aÂ wideÂ rangeÂ ofÂ inquiries.Â PoweredÂ byÂ theÂ GPT-3.5Â architecture,Â itÂ leveragesÂ extensiveÂ trainingÂ dataÂ toÂ provideÂ accurateÂ andÂ coherentÂ responses.Â WithÂ itsÂ naturalÂ languageÂ processingÂ capabilities,Â ChatGPTÂ aimsÂ toÂ enhanceÂ communicationÂ andÂ offerÂ valuableÂ information,Â makingÂ itÂ aÂ valuableÂ toolÂ inÂ variousÂ domains.",
)
```

```python
{'score': 0.32861292362213135,
 'start': 277,
 'end': 332,
 'answer': 'to enhance communication and offer valuable information'}
```

---

### **Summarization**

```python
fromÂ transformersÂ importÂ pipeline

summarizerÂ =Â pipeline("summarization")
summarizer(
Â Â Â Â """
Â Â Â Â ChatGPTÂ isÂ anÂ impressiveÂ featÂ ofÂ artificialÂ intelligence,Â revolutionizingÂ theÂ wayÂ weÂ interactÂ withÂ computerÂ systems.Â DevelopedÂ byÂ OpenAI,Â itÂ isÂ builtÂ uponÂ theÂ powerfulÂ GPT-3.5Â architecture,Â whichÂ enablesÂ itÂ toÂ generateÂ human-likeÂ responsesÂ toÂ userÂ queries.
WithÂ aÂ vastÂ amountÂ ofÂ trainingÂ data,Â ChatGPTÂ hasÂ beenÂ exposedÂ toÂ aÂ diverseÂ rangeÂ ofÂ topics,Â makingÂ itÂ well-equippedÂ toÂ provideÂ accurateÂ andÂ insightfulÂ information.Â WhetherÂ youÂ needÂ assistanceÂ withÂ generalÂ knowledge,Â technicalÂ inquiries,Â orÂ evenÂ creativeÂ writingÂ prompts,Â ChatGPTÂ canÂ offerÂ valuableÂ guidance.
TheÂ naturalÂ languageÂ processingÂ capabilitiesÂ ofÂ ChatGPTÂ allowÂ itÂ toÂ understandÂ andÂ respondÂ toÂ aÂ wideÂ arrayÂ ofÂ linguisticÂ nuances.Â ItÂ canÂ decipherÂ theÂ contextÂ ofÂ aÂ questionÂ andÂ generateÂ coherentÂ andÂ contextuallyÂ appropriateÂ answers.Â Moreover,Â ChatGPTÂ canÂ engageÂ inÂ conversationalÂ dialogues,Â adaptingÂ itsÂ responsesÂ toÂ maintainÂ aÂ seamlessÂ interaction.
WhileÂ ChatGPTÂ excelsÂ atÂ providingÂ information,Â itÂ isÂ importantÂ toÂ noteÂ thatÂ itÂ operatesÂ withinÂ theÂ limitsÂ ofÂ itsÂ trainingÂ data.Â ItÂ mayÂ occasionallyÂ produceÂ incorrectÂ orÂ incompleteÂ answers,Â andÂ itÂ lacksÂ theÂ abilityÂ toÂ verifyÂ theÂ accuracyÂ ofÂ theÂ informationÂ itÂ provides.Â UsersÂ shouldÂ exerciseÂ criticalÂ thinkingÂ andÂ verifyÂ factsÂ independentlyÂ whenÂ necessary.
OpenAIÂ hasÂ implementedÂ measuresÂ toÂ ensureÂ theÂ responsibleÂ useÂ ofÂ ChatGPT,Â suchÂ asÂ itsÂ knowledgeÂ cutoffÂ dateÂ andÂ theÂ abilityÂ toÂ flagÂ andÂ addressÂ biasedÂ orÂ inappropriateÂ content.Â TheseÂ effortsÂ aimÂ toÂ createÂ aÂ safeÂ andÂ reliableÂ environmentÂ forÂ users.
AsÂ anÂ AIÂ languageÂ model,Â ChatGPTÂ isÂ continuouslyÂ evolving.Â OpenAIÂ activelyÂ seeksÂ userÂ feedbackÂ toÂ improveÂ itsÂ performanceÂ andÂ addressÂ anyÂ limitations.Â TheÂ goalÂ isÂ toÂ refineÂ andÂ enhanceÂ ChatGPT'sÂ capabilities,Â makingÂ itÂ anÂ evenÂ moreÂ valuableÂ toolÂ forÂ individualsÂ andÂ businessesÂ alike.
Overall,Â ChatGPTÂ representsÂ aÂ significantÂ advancementÂ inÂ conversationalÂ AI,Â bridgingÂ theÂ gapÂ betweenÂ humansÂ andÂ machines.Â ItÂ hasÂ theÂ potentialÂ toÂ transformÂ variousÂ industriesÂ andÂ revolutionizeÂ theÂ wayÂ weÂ interactÂ withÂ technology,Â pavingÂ theÂ wayÂ forÂ aÂ futureÂ whereÂ intelligentÂ virtualÂ assistantsÂ areÂ anÂ integralÂ partÂ ofÂ ourÂ dailyÂ lives.
"""
)
```

Output

```bash
[{'summary_text': ' ChatGPT is an impressive feat of artificial intelligence, revolutionizing the way we interact with computer systems . It is built upon the powerful GPT-3.5 architecture, which enables it to generate human-like responses to user queries . It can decipher the context of a question and generate coherent and contextually appropriate answers .'}]
```

---

### Translation

```python
#Â InstallÂ sentencepiece
!pipÂ installÂ transformers[sentencepiece]
# restart the kernel
```

```python
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.30.2)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.1)
Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.22.4)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.1)
Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2022.10.31)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.27.1)
Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.13.3)
Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.3.1)
Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.65.0)
Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)
Requirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (2023.4.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (4.5.0)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (1.26.15)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.12)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4)
```

**Tranlation Model list :** [**https://huggingface.co/models?pipeline\_tag=translation&sort=downloads**](https://huggingface.co/models?pipeline_tag=translation&sort=downloads)

```python
fromÂ transformersÂ importÂ pipeline
translatesÂ =Â pipeline("translation",model="Helsinki-NLP/opus-mt-en-hi")
translates("AppleÂ hasÂ anÂ ecosystemÂ ofÂ devices.")
```

```bash
[{'translation_text': 'à¤à¤ªà¥à¤ªà¤² à¤‰à¤ªà¤•à¤°à¤£à¥‹à¤‚ à¤•à¤¾ à¤à¤• à¤ªà¤°à¥à¤¯à¤¾à¤µà¤°à¤£ à¤¹à¥ˆ.'}]
```

```python
#Â model="Helsinki-NLP/opus-mt-en-hi"Â translateÂ en(english)Â toÂ hi(hindi)
#Â model="Helsinki-NLP/opus-mt-hi-en"Â translateÂ hi(hindi)Â toÂ en(english)

translatesÂ =Â pipeline("translation",model="Helsinki-NLP/opus-mt-hi-en")
translates("à¤à¤ªà¥à¤ªà¤²Â à¤‰à¤ªà¤•à¤°à¤£à¥‹à¤‚Â à¤•à¤¾Â à¤à¤•Â à¤ªà¤°à¥à¤¯à¤¾à¤µà¤°à¤£Â à¤¹à¥ˆ.")
```

```bash
[{'translation_text': 'The Appall devices have an environment.'}]
```

### All the code mentioned is available in the Colab notebook.

<center>
<a target="_blank" href="https://colab.research.google.com/github/suyash-srivastava-dev/A4I/blob/main/Colab/NLP_01.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" />
</a>
</center>